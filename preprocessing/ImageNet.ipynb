{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ImageNet.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOz1s++FQfyn1h/Ra1x/6M+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["[MobileNetV2](https://keras.io/api/applications/mobilenet/#mobilenetv2-function)\n","\n","[keras.applications.mobilenet_v2.preprocess_input](https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet_v2/preprocess_input)\n","\n","[https://keras.io/api/preprocessing/image/#load_img-function](tf.keras.preprocessing.image_dataset_from_directory)"],"metadata":{"id":"OKrYIKWZ7DjS"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y489-xQBoiIf"},"outputs":[],"source":["# !pip install keras\n","# !pip install tensorflow"]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import numpy as np\n","\n","from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras import Model\n","\n","from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","from keras.applications.mobilenet_v2 import preprocess_input"],"metadata":{"id":"BbCQBrWay2BR","executionInfo":{"status":"ok","timestamp":1653744721682,"user_tz":180,"elapsed":2,"user":{"displayName":"Alice Valença De Lorenci","userId":"13029990336363249926"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["# mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","path = '/content/drive/Shareddrives/Machine Learning/'\n","data_path = '/content/drive/Shareddrives/Machine Learning/' + 'data/'\n","code_path = '/content/drive/Shareddrives/Machine Learning/' + 'code/'\n","image_path = '/content/drive/My Drive/2022.1/MACHINE_LEARNING/TRAB_ALZHEIMER/data/ADNI_PNG/'\n","\n","features_file = 'features1'\n","classes_file = 'classes1'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jMsXF6W0vg33","executionInfo":{"status":"ok","timestamp":1653744700089,"user_tz":180,"elapsed":2536,"user":{"displayName":"Alice Valença De Lorenci","userId":"13029990336363249926"}},"outputId":"0f19b1bc-396c-40d6-f850-b801f2285af5"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# get image name\n","import os\n","imgs = np.array( os.listdir( image_path ) )\n","imgs = np.c_[ imgs, np.zeros( len(imgs) ) ] # column 0: image name / column 1: -\n","\n","# extract image class\n","imgs[:,1] = [ (name.split('_')[-1]).split('.')[0] for name in imgs[:,0] ]\n","\n","# save classes\n","np.savetxt( data_path + classes_file + '.csv', imgs, delimiter=',', fmt=\"%s\" )"],"metadata":{"id":"aDFC6PddMac4","executionInfo":{"status":"ok","timestamp":1653744645366,"user_tz":180,"elapsed":21368,"user":{"displayName":"Alice Valença De Lorenci","userId":"13029990336363249926"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["# load full model\n","extractor = MobileNetV2()\n","\n","# remove the output layer\n","extractor = Model(inputs=extractor.inputs, outputs=extractor.layers[-2].output)\n","\n","# extractor.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vl2jzf2DygmZ","executionInfo":{"status":"ok","timestamp":1653475009500,"user_tz":180,"elapsed":2488,"user":{"displayName":"Alice Valença De Lorenci","userId":"13029990336363249926"}},"outputId":"eb282648-6350-488e-f95d-d5c96dfbae9d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n","14540800/14536120 [==============================] - 0s 0us/step\n","14548992/14536120 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["# build dataset for feature extraction\n","dataset = np.array( [ [ extractor.predict(\\\n","                                          preprocess_input(\\\n","                                                           img_to_array(\\\n","                                                                        load_img( path + imgs[i,0], target_size=(224, 224) ) \\\n","                                                                        ).reshape( (1, 224, 224, 3) ) ) )[0],\\\n","                       print( '\\r', i, end='' ) ][0] \\\n","                     for i in range( imgs.shape[0] ) ] )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"CWP6EYbbypeE","executionInfo":{"status":"ok","timestamp":1653483675278,"user_tz":180,"elapsed":1721486,"user":{"displayName":"Alice Valença De Lorenci","userId":"13029990336363249926"}},"outputId":"63a9953f-ede2-4c00-e826-c40d18b74f7c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" 19519"]},{"output_type":"execute_result","data":{"text/plain":["\"\\ndataset = np.empty( (1, 224, 224, 3) )\\n\\nfor i in range( imgs.shape[0] ):\\n  print( '\\r', i, end='' )\\n\\n  # load an image from file\\n  image = load_img( path + imgs[i,0], target_size=(224, 224) )\\n  # convert the image pixels to a numpy array\\n  image = img_to_array( image )\\n  # reshape data for the model\\n  image = image.reshape( (1, image.shape[0], image.shape[1], image.shape[2]) )\\n\\n  dataset = np.append( dataset, image, axis=0 )\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["dataset.shape"],"metadata":{"id":"MZz57buf3w8R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save extracted features\n","np.savez_compressed( data_path + features_file + '.npz', dataset )\n","np.savetxt( data_path + features_file + '.csv', dataset, delimiter=',' )"],"metadata":{"id":"dO1OwZMz3Jji"},"execution_count":null,"outputs":[]}]}